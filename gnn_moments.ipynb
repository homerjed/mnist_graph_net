{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from typing import (\n",
    "  Tuple, List, Dict, Any, Sequence, Callable)\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr \n",
    "import jraph\n",
    "import optax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_mnist import load_mnist\n",
    "from mnist_to_graphs import (\n",
    "  get_mnist_graphs, \n",
    "  get_rotated_mnist_graphs,\n",
    "  pad_graph_to_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "Array = jnp.ndarray\n",
    "Graph = jraph.GraphsTuple\n",
    "\n",
    "N_GRAPHS = 1024\n",
    "BATCH_SIZE = 16\n",
    "N_STEPS = 5_000\n",
    "PAD_VALUE = 8128 \n",
    "R_LINK = 0.15 #2. #1.5\n",
    "F = 8\n",
    "E = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for redshifts:\n",
      "[0.0, 0.5, 1.0]\n",
      "at resolution x=1024 with R values:\n",
      "['5.0', '10.0', '15.0', '20.0'].\n"
     ]
    }
   ],
   "source": [
    "def get_R_z_string(R_values, z_values, n_moments_calculate=3):\n",
    "    if isinstance(R_values, list):\n",
    "        if len(R_values) == len(all_R_values):\n",
    "            R_string = \"all\"\n",
    "        else:\n",
    "            R_string = \"_\".join([str(float(R)) for R in R_values])\n",
    "    else:\n",
    "        R_string = str(R_values)\n",
    "    if isinstance(z_values, list):\n",
    "        if len(z_values) == len(all_redshifts):\n",
    "            z_string = \"all\"\n",
    "        else:\n",
    "            z_string = \"_\".join([str(float(z)) for z in z_values])\n",
    "    else:\n",
    "        z_string = str(z_values)\n",
    "\n",
    "    return f\"x={resolution}_R={R_string}_z={z_string}_nm={n_moments_calculate}\"\n",
    "\n",
    "prng_seq = hk.PRNGSequence(0)\n",
    "\n",
    "data_dir = \"/Users/Jed.Homer/phd/lfi/jaxdelfi/data/\"\n",
    "resolution = 1024 \n",
    "all_redshifts = [0., 0.5, 1., 2., 3.]\n",
    "all_R_values = [\"5.0\", \"10.0\", \"15.0\", \"20.0\", \"25.0\", \"30.0\"]\n",
    "\n",
    "redshifts = all_redshifts[:3]\n",
    "R_values = all_R_values[:4]\n",
    "\n",
    "R_idx = [all_R_values.index(R) for R in R_values]\n",
    "z_idx = [redshifts.index(z) for z in redshifts]\n",
    "\n",
    "print(f\"Running for redshifts:\\n{redshifts}\\nat resolution x={resolution} with R values:\\n{R_values}.\")\n",
    "\n",
    "Rz_string = get_R_z_string(R_values, redshifts, n_moments_calculate=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data\n",
    "* for each moments datavector, make fully connected subgraph for each redshift, then concatenate all the redshift graphs together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 5), (2000, 3, 4, 3), (3, 4, 3))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = jnp.array([0.3175, 0.049, 0.6711, 0.9624, 0.834])\n",
    "parameters = jnp.load(\n",
    "        os.path.join(data_dir, f\"ALL_PDFS_PARAMS.npy\")) \n",
    "simulations = jnp.load(\n",
    "    os.path.join(data_dir, f\"CALCULATED_PDF_MOMENTS_{Rz_string}.npy\"))\n",
    "fiducial_dv = jnp.load(\n",
    "    os.path.join(data_dir, f'fiducial_moments_unflat_{Rz_string}.npy')).mean(axis=0)\n",
    "\n",
    "n_sims, parameter_dim = parameters.shape\n",
    "data_dim = np.prod(fiducial_dv.shape)\n",
    "\n",
    "parameters.shape, simulations.shape, fiducial_dv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_subgraphs(moments, parameters):\n",
    "    # Vmapping, so this is z-axis\n",
    "    all_g_z = []\n",
    "    for mz in moments:\n",
    "        # print(mz.shape, np.prod(mz.shape))\n",
    "        g_z = jraph.get_fully_connected_graph(\n",
    "            node_features=mz.flatten(),\n",
    "            n_node_per_graph=np.prod(mz.shape),\n",
    "            n_graph=1,\n",
    "            #global_features=parameters, # maybe just parameters for main_graph not subgraphs?\n",
    "            add_self_edges=True)\n",
    "        all_g_z.append(g_z)\n",
    "    return all_g_z \n",
    "\n",
    "def make_graph_from_subgraphs(subgraphs, parameters):\n",
    "    # make one graph from fully connected redshift-subgraphs\n",
    "    return jraph.GraphsTuple(\n",
    "        nodes=jnp.concatenate([g_z.nodes for g_z in subgraphs]),\n",
    "        edges=None,# edges=jnp.concatenate([g_z.edges for g_z in subgraphs]), # edge FEATURES not senders/receivers\n",
    "        # Since graph is made of subgraphs, need to re-index S and R for main_graph indexing...\n",
    "        senders=jnp.concatenate([g_z.n_node * n + g_z.senders for n, g_z in enumerate(subgraphs)]),\n",
    "        receivers=jnp.concatenate([g_z.n_node * n + g_z.receivers for n, g_z in enumerate(subgraphs)]),\n",
    "        # senders=jnp.concatenate([g_z.senders for g_z in subgraphs]),\n",
    "        # receivers=jnp.concatenate([g_z.receivers for g_z in subgraphs]),\n",
    "        n_node=sum([g_z.n_node for g_z in subgraphs]),\n",
    "        n_edge=sum([g_z.n_edge for g_z in subgraphs]),\n",
    "        globals=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jed.Homer/miniconda3/envs/jraph/lib/python3.10/site-packages/jraph/_src/utils.py:882: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  num_node_features = jax.tree_leaves(node_features)[0].shape[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((36,),\n",
       " None,\n",
       " DeviceArray([0.3175, 0.049 , 0.6711, 0.9624, 0.834 ], dtype=float32),\n",
       " (432,),\n",
       " (432,))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subgraphs = make_subgraphs(fiducial_dv, alpha[None, :])\n",
    "main_graph = make_graph_from_subgraphs(subgraphs, alpha)\n",
    "# print(subgraphs[0])\n",
    "main_graph.nodes.shape, main_graph.edges, main_graph.globals, main_graph.senders.shape, main_graph.receivers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(35, dtype=int32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_graph.senders.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "3 1\n",
      "4 1\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 1\n",
      "9 1\n",
      "10 1\n",
      "11 1\n",
      "0 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "6 2\n",
      "7 2\n",
      "8 2\n",
      "9 2\n",
      "10 2\n",
      "11 2\n"
     ]
    }
   ],
   "source": [
    "# main_graph.senders[:36]\n",
    "\n",
    "A = np.zeros((36, 36))\n",
    "# for i in range(36):\n",
    "#     for j in range(36):\n",
    "\n",
    "for n in range(36):\n",
    "    # non-directed graph => if sender then receiver => use only senders?\n",
    "    print(main_graph.senders[n], main_graph.receivers[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix(sender_indices, receiver_indices, n_nodes=None):\n",
    "    # Determine the number of nodes in the graph if not provided\n",
    "    if n_nodes is None:\n",
    "        n_nodes = max(max(sender_indices), max(receiver_indices)) + 1\n",
    "\n",
    "    # Create an empty adjacency matrix\n",
    "    adj_matrix = np.zeros((n_nodes, n_nodes))\n",
    "\n",
    "    # Set entries in the adjacency matrix for each edge\n",
    "    for sender, receiver in zip(sender_indices, receiver_indices):\n",
    "        adj_matrix[sender, receiver] = 1 \n",
    "        adj_matrix[receiver, sender] = 1 \n",
    "\n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = adjacency_matrix(subgraphs[0].senders, subgraphs[0].receivers)\n",
    "# print(A)\n",
    "# plt.imshow(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expect three squares on diagonal: FULLY connected subgraphs\n",
    "A = adjacency_matrix(main_graph.senders, main_graph.receivers)\n",
    "plt.imshow(A, cmap=\"gray_r\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "layernorm_kwargs = dict(axis=1, create_scale=True, create_offset=True)\n",
    "\n",
    "class LinearResNet(hk.Module):\n",
    "  def __init__(\n",
    "    self, \n",
    "    hidden_sizes: Sequence[int],\n",
    "    activation: Callable = jax.nn.leaky_relu,\n",
    "    activate_final: bool = False):\n",
    "    super().__init__()\n",
    "    self.hidden_sizes = hidden_sizes\n",
    "    self.activation = activation\n",
    "    self.activate_final = activate_final\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # assert x.shape[-1] == self.hidden_size, (\n",
    "    #   \"Input must be hidden size.\")\n",
    "    z = x\n",
    "    for f in self.hidden_sizes:\n",
    "      h = self.activation(z)\n",
    "      h = hk.LayerNorm(**layernorm_kwargs)(h)\n",
    "      h = hk.Linear(f)(h)\n",
    "      h = self.activation(h)\n",
    "      h = hk.LayerNorm(**layernorm_kwargs)(h)\n",
    "      h = hk.Linear(f, w_init=jnp.zeros)(h)\n",
    "      z = z + h \n",
    "    return self.activation(z) if self.activate_final else z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jraph.concatenated_args\n",
    "def edge_update_fn(feats: Array) -> Array:\n",
    "  \"\"\" Edge update function for graph net. \"\"\"\n",
    "  net = hk.Sequential([\n",
    "    hk.Linear(F), LinearResNet([F, F, F])])\n",
    "    # hk.Linear(F), hk.nets.MLP([F, F, F])])\n",
    "  return net(feats)\n",
    "\n",
    "@jraph.concatenated_args \n",
    "def node_update_fn(feats: Array) -> Array:\n",
    "  \"\"\" Node update function for graph net. \"\"\"\n",
    "  net = hk.Sequential([\n",
    "    hk.Linear(F), LinearResNet([F, F, F])])\n",
    "    # hk.Linear(F), hk.nets.MLP([F, F, F])])\n",
    "  return net(feats)\n",
    "\n",
    "@jraph.concatenated_args\n",
    "def update_global_fn(feats: Array) -> Array:\n",
    "  \"\"\" Global update function for graph net. \"\"\"\n",
    "  net = hk.Sequential([\n",
    "    hk.Linear(F), \n",
    "    #LinearResNet([F, F, F], activate_final=True),\n",
    "    hk.nets.MLP([F, F, F], activate_final=True),\n",
    "    hk.Linear(parameter_dim, with_bias=False)]) # output summary of parameter dim\n",
    "  return net(feats)\n",
    "\n",
    "def LayerNormLinear(x):\n",
    "    return hk.Linear(E, with_bias=False)(hk.LayerNorm(**layernorm_kwargs)(x))\n",
    "\n",
    "def net_fn(graph: Graph) -> Graph:\n",
    "  \"\"\" \n",
    "    Default aggregator functions for edges, global edges, global nodes \n",
    "    are \"segment_sum\"\n",
    "  \"\"\"\n",
    "  embedder = jraph.GraphMapFeatures(\n",
    "    # embed_edge_fn=LayerNormLinear, #hk.Linear(E, with_bias=False), \n",
    "    embed_node_fn=LayerNormLinear, #hk.Linear(E, with_bias=False), \n",
    "    embed_global_fn=LayerNormLinear) #hk.Linear(E, with_bias=False))\n",
    "  net = jraph.GraphNetwork(\n",
    "    update_node_fn=node_update_fn,\n",
    "    # update_edge_fn=edge_update_fn,\n",
    "    update_edge_fn=None,\n",
    "    update_global_fn=update_global_fn)\n",
    "  graph = embedder(graph)\n",
    "#   for _ in range(3):\n",
    "  graph = net(graph)\n",
    "  return graph\n",
    "  #return net(embedder(graph)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed = []\n",
    "for n in range(N_GRAPHS):\n",
    "    g = make_graph_from_subgraphs(\n",
    "        make_subgraphs(\n",
    "            simulations[n], parameters[n]), parameters[n])\n",
    "    l = parameters[n]\n",
    "    dataset_processed.append(dict(input_graph=g, target=l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(36,), (36,), (36,), (36,), (36,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([36, 36, 36, 36, 36], dtype=int32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs, ls = [], []\n",
    "for _ in range(5):\n",
    "    gl = dataset_processed[_]\n",
    "    g, l = gl.values()\n",
    "    gs.append(g), ls.append(l)\n",
    "\n",
    "g_all = jraph.batch(gs)\n",
    "print([g.nodes.shape for g in gs])\n",
    "g_all.nodes.shape\n",
    "g_all.n_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(\n",
    "  params: hk.Params, \n",
    "  graph: Graph, \n",
    "  label: Array,\n",
    "  net: Graph) -> Tuple[Array, Array]:\n",
    "  \"\"\"Computes loss and accuracy.\"\"\"\n",
    "\n",
    "  pred_graph = net.apply(params, graph)\n",
    "  print(\"pred graph globals\", pred_graph.globals.shape)\n",
    "\n",
    "  # Output of GNN and target: one hot encoded MNIST labels\n",
    "  # preds = jax.nn.log_softmax(pred_graph.globals)\n",
    "  preds = pred_graph.globals\n",
    "\n",
    "  mask = jraph.get_graph_padding_mask(pred_graph)\n",
    "\n",
    "  # Cross entropy loss.\n",
    "  print(\"PREDS/TARGETS\", preds.shape, label.shape)\n",
    "  # loss = -(preds * label * mask[:, None]).mean()\n",
    "  loss = (jnp.square(jnp.subtract(preds, label)) * mask[:, None]).mean()\n",
    "\n",
    "  return loss, (None,)\n",
    " \n",
    "\n",
    "def train(\n",
    "  dataset: List[Dict[str, Any]], \n",
    "  num_train_steps: int) -> Tuple[hk.Params, List, List]:\n",
    "\n",
    "  key = jr.PRNGKey(0)\n",
    "\n",
    "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "\n",
    "  graph = dataset[0]['input_graph']\n",
    "  graph = pad_graph_to_value(graph, PAD_VALUE)\n",
    "  params = net.init(key, graph)\n",
    "\n",
    "  print(f\"n_params = {sum(x.size for x in jax.tree_util.tree_leaves(params)):.2E}\")\n",
    "\n",
    "  # Initialize the optimizer.\n",
    "  opt_init, opt_update = optax.adabelief(2e-4)\n",
    "  opt_state = opt_init(params)\n",
    "\n",
    "  compute_loss_fn = partial(compute_loss, net=net)\n",
    "  compute_loss_fn = jax.jit(\n",
    "    jax.value_and_grad(compute_loss_fn, has_aux=True))\n",
    "\n",
    "  losses, accs = [], []\n",
    "  for _ in range(num_train_steps):\n",
    "    key, key_idx = jr.split(key)\n",
    "\n",
    "    if BATCH_SIZE > 1:\n",
    "        idx = jr.randint(key_idx, shape=(BATCH_SIZE,), minval=0, maxval=N_GRAPHS)\n",
    "        gs, ls = [], []\n",
    "        for i in idx:\n",
    "            g, l = dataset[int(i)].values()\n",
    "            gs.append(g), ls.append(l)\n",
    "        graph = jraph.batch(gs)\n",
    "        label = jnp.concatenate(ls)\n",
    "    else:\n",
    "        idx = int(jr.randint(key_idx, shape=(BATCH_SIZE,), minval=0, maxval=N_GRAPHS))\n",
    "        graph, label = dataset[idx].values()\n",
    "\n",
    "    \"\"\" Should remove graph label, for model to generate itself. \"\"\"\n",
    "    # graph = graph._replace(globals=jnp.zeros([graph.n_node.shape[0], 1]))\n",
    "    graph = pad_graph_to_value(graph, PAD_VALUE)\n",
    "\n",
    "    # Since padding is implemented with pad_with_graphs, an extra graph has\n",
    "    # been added to the batch, which means there should be an extra label.\n",
    "    \"\"\" This label gets masked out. \"\"\"\n",
    "    label = jnp.concatenate([label, jnp.zeros((1, parameter_dim))])\n",
    "\n",
    "    (loss, (acc, pred)), grad = compute_loss_fn(params, graph, label)\n",
    "    updates, opt_state = opt_update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    if _ % 100 == 0:\n",
    "      print(f'\\rstep: {_:06d}, ' +\n",
    "            f'loss: {loss:.4f}, ' + \n",
    "            f'acc: {100. * acc:.4f}% ' + \n",
    "            f'l: {label.argmax(axis=1)} ' +\n",
    "            f'l_: {pred}', end=\"\")\n",
    "    losses.append(loss)\n",
    "    accs.append(acc)\n",
    "\n",
    "  print('Training finished')\n",
    "  return params, losses, accs\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "  dataset: List[Dict[str, Any]],\n",
    "  params: hk.Params) -> Tuple[Array, Array]:\n",
    "\n",
    "  # Transform impure `net_fn` to pure functions with hk.transform.\n",
    "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "\n",
    "  # Get a candidate graph and label to initialize the network.\n",
    "  graph = dataset[0]['input_graph']\n",
    "\n",
    "  accumulated_loss = 0.\n",
    "  accumulated_accuracy = 0.\n",
    "\n",
    "  compute_loss_fn = jax.jit(partial(compute_loss, net=net))\n",
    "  for idx in range(len(dataset)):\n",
    "    graph = dataset[idx]['input_graph']\n",
    "    label = dataset[idx]['target']\n",
    "\n",
    "    graph = pad_graph_to_value(graph, PAD_VALUE)\n",
    "    label = jnp.concatenate([label, jnp.zeros((1, parameter_dim))])\n",
    "\n",
    "    graph = net.apply(params, graph)\n",
    "\n",
    "    loss, acc = compute_loss_fn(params, graph, label)\n",
    "\n",
    "    accumulated_accuracy += acc\n",
    "    accumulated_loss += loss\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "      print(f'Evaluated {idx + 1} graphs')\n",
    "\n",
    "  print('Completed evaluation.')\n",
    "  loss = accumulated_loss / idx\n",
    "  accuracy = accumulated_accuracy / idx\n",
    "  print(f'Eval loss: {loss:.4f}, accuracy {accuracy:.4f}')\n",
    "  return loss, accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4157  0.04765 0.6087  0.8165  0.9189  0.     ]\n",
      "[0.4157  0.04765 0.6087  0.8165  0.9189  0.     ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: (2,) and requested shape (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[212], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(graph\u001b[39m.\u001b[39mglobals)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(graph\u001b[39m.\u001b[39mglobals)\n\u001b[0;32m---> 15\u001b[0m params \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49minit(key, graph)\n\u001b[1;32m     17\u001b[0m graph \u001b[39m=\u001b[39m dataset_processed[ix2][\u001b[39m'\u001b[39m\u001b[39minput_graph\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m l \u001b[39m=\u001b[39m dataset_processed[ix2][\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/transform.py:114\u001b[0m, in \u001b[0;36mwithout_state.<locals>.init_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   params, state \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49minit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    115\u001b[0m   \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mthen use `hk.transform_with_state`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/transform.py:338\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.init_fn\u001b[0;34m(rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    337\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    339\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    340\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[208], line 46\u001b[0m, in \u001b[0;36mnet_fn\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     44\u001b[0m   graph \u001b[39m=\u001b[39m embedder(graph)\n\u001b[1;32m     45\u001b[0m \u001b[39m#   for _ in range(3):\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m   graph \u001b[39m=\u001b[39m net(graph)\n\u001b[1;32m     47\u001b[0m   \u001b[39mreturn\u001b[39;00m graph\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jraph/_src/models.py:178\u001b[0m, in \u001b[0;36mGraphNetwork.<locals>._ApplyGraphNet\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    175\u001b[0m received_attributes \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m n: n[receivers], nodes)\n\u001b[1;32m    176\u001b[0m \u001b[39m# Here we scatter the global features to the corresponding edges,\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m# giving us tensors of shape [num_edges, global_feat].\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m global_edge_attributes \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39;49mtree_map(\u001b[39mlambda\u001b[39;49;00m g: jnp\u001b[39m.\u001b[39;49mrepeat(\n\u001b[1;32m    179\u001b[0m     g, n_edge, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, total_repeat_length\u001b[39m=\u001b[39;49msum_n_edge), globals_)\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m update_edge_fn:\n\u001b[1;32m    182\u001b[0m   edges \u001b[39m=\u001b[39m update_edge_fn(edges, sent_attributes, received_attributes,\n\u001b[1;32m    183\u001b[0m                          global_edge_attributes)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/tree_util.py:200\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    198\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    199\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39;49munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;49;00m xs \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/tree_util.py:200\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    198\u001b[0m leaves, treedef \u001b[39m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[1;32m    199\u001b[0m all_leaves \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treedef\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rest]\n\u001b[0;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m treedef\u001b[39m.\u001b[39munflatten(f(\u001b[39m*\u001b[39;49mxs) \u001b[39mfor\u001b[39;00m xs \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jraph/_src/models.py:178\u001b[0m, in \u001b[0;36mGraphNetwork.<locals>._ApplyGraphNet.<locals>.<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    175\u001b[0m received_attributes \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m n: n[receivers], nodes)\n\u001b[1;32m    176\u001b[0m \u001b[39m# Here we scatter the global features to the corresponding edges,\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m# giving us tensors of shape [num_edges, global_feat].\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m global_edge_attributes \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m g: jnp\u001b[39m.\u001b[39;49mrepeat(\n\u001b[1;32m    179\u001b[0m     g, n_edge, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, total_repeat_length\u001b[39m=\u001b[39;49msum_n_edge), globals_)\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m update_edge_fn:\n\u001b[1;32m    182\u001b[0m   edges \u001b[39m=\u001b[39m update_edge_fn(edges, sent_attributes, received_attributes,\n\u001b[1;32m    183\u001b[0m                          global_edge_attributes)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2409\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(a, repeats, axis, total_repeat_length)\u001b[0m\n\u001b[1;32m   2407\u001b[0m   repeats \u001b[39m=\u001b[39m ravel(repeats)\n\u001b[1;32m   2408\u001b[0m   \u001b[39mif\u001b[39;00m ndim(a) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2409\u001b[0m     repeats \u001b[39m=\u001b[39m broadcast_to(repeats, [a\u001b[39m.\u001b[39;49mshape[axis]])\n\u001b[1;32m   2411\u001b[0m \u001b[39m# Special case when a is a scalar.\u001b[39;00m\n\u001b[1;32m   2412\u001b[0m \u001b[39mif\u001b[39;00m ndim(a) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/numpy/util.py:403\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[0;34m(arr, shape)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m nlead \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m compatible:\n\u001b[1;32m    402\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mIncompatible shapes for broadcasting: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and requested shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 403\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(arr_shape, shape))\n\u001b[1;32m    404\u001b[0m diff, \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(\u001b[39mtuple\u001b[39m(\u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39msymbolic_equal_dim(arr_d, shape_d)\n\u001b[1;32m    405\u001b[0m                        \u001b[39mfor\u001b[39;00m arr_d, shape_d \u001b[39min\u001b[39;00m safe_zip(arr_shape, shape_tail)))\n\u001b[1;32m    406\u001b[0m new_dims \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mrange\u001b[39m(nlead)) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(nlead \u001b[39m+\u001b[39m diff)\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: (2,) and requested shape (8,)"
     ]
    }
   ],
   "source": [
    "key = jr.PRNGKey(0)\n",
    "key, _ = jr.split(key)\n",
    "\n",
    "net = hk.without_apply_rng(hk.transform(net_fn))\n",
    "\n",
    "ix1, ix2 = jr.randint(key, (2,), 0, len(dataset_processed))\n",
    "\n",
    "graph = dataset_processed[ix1]['input_graph']\n",
    "l = dataset_processed[ix1]['target']\n",
    "graph = pad_graph_to_value(graph, PAD_VALUE)\n",
    "print(graph.globals)\n",
    "\n",
    "print(graph.globals)\n",
    "\n",
    "params = net.init(key, graph)\n",
    "\n",
    "graph = dataset_processed[ix2]['input_graph']\n",
    "l = dataset_processed[ix2]['target']\n",
    "graph = pad_graph_to_value(graph, PAD_VALUE)\n",
    "\n",
    "y_ = net.apply(params, graph)\n",
    "print(\"net out\", y_.globals.shape)\n",
    "\n",
    "mask = jraph.get_graph_padding_mask(y_)\n",
    "print(mask)\n",
    "\n",
    "jnp.argmax(y_.globals[mask], axis=1), l.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before pad (64, 1) (372, 3) (1, 10)\n",
      "after pad (8129, 1) (8128, 3) (2, 10)\n"
     ]
    }
   ],
   "source": [
    "graph = dataset_processed[ix2]['input_graph']\n",
    "print(\"before pad\", graph.nodes.shape, graph.edges.shape, graph.globals.shape)\n",
    "l = dataset_processed[ix2]['target']\n",
    "graph = pad_graph_to_value(graph, PAD_VALUE)\n",
    "print(\"after pad\", graph.nodes.shape, graph.edges.shape, graph.globals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_params = 5.98E+04\n",
      "pred graph globals (9, 10)\n",
      "PREDS/TARGETS (9, 10) (9, 10)\n",
      "pred graph global Traced<ShapedArray(int32[9])>with<DynamicJaxprTrace(level=0/1)>\n",
      "label Traced<ShapedArray(int32[9])>with<DynamicJaxprTrace(level=0/1)>\n",
      "step: 004900, loss: 0.0285, acc: 87.5000 l: [9 1 1 4 1 2 1 7 0] l_: [9 1 1 4 1 0 1 7 1]]Training finished\n"
     ]
    }
   ],
   "source": [
    "params, losses, accs = train(dataset_processed, num_train_steps=N_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m ax \u001b[39m=\u001b[39m axs[\u001b[39m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m steps \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, N_STEPS, \u001b[39m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m ax\u001b[39m.\u001b[39msemilogy(steps, losses[::\u001b[39m10\u001b[39m])\n\u001b[1;32m      5\u001b[0m ax \u001b[39m=\u001b[39m axs[\u001b[39m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m steps \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, N_STEPS, \u001b[39m40\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, dpi=200, figsize=(8.,4.))\n",
    "ax = axs[0]\n",
    "steps = range(0, N_STEPS, 10)\n",
    "ax.semilogy(steps, losses[::10])\n",
    "ax = axs[1]\n",
    "steps = range(0, N_STEPS, 40)\n",
    "ax.plot(steps, accs[::40])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label [5 0] [8 9]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'linear_1/w' with retrieved shape (1, 32) does not match shape=[32, 32] dtype=dtype('float32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[579], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(dataset_processed, params)\n",
      "Cell \u001b[0;32mIn[571], line 113\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m graph \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mapply(params, graph)\n\u001b[1;32m    111\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), graph\u001b[39m.\u001b[39mglobals\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 113\u001b[0m loss, acc \u001b[39m=\u001b[39m compute_loss_fn(params, graph, label)\n\u001b[1;32m    115\u001b[0m accumulated_accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m acc\n\u001b[1;32m    116\u001b[0m accumulated_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[571], line 8\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(params, graph, label, net)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_loss\u001b[39m(\n\u001b[1;32m      2\u001b[0m   params: hk\u001b[39m.\u001b[39mParams, \n\u001b[1;32m      3\u001b[0m   graph: Graph, \n\u001b[1;32m      4\u001b[0m   label: Array,\n\u001b[1;32m      5\u001b[0m   net: Graph) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Array, Array]:\n\u001b[1;32m      6\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Computes loss and accuracy.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m   pred_graph \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mapply(params, graph)\n\u001b[1;32m      9\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpred graph globals\u001b[39m\u001b[39m\"\u001b[39m, pred_graph\u001b[39m.\u001b[39mglobals\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m   \u001b[39m# Output of GNN and target: one hot encoded MNIST labels\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/multi_transform.py:298\u001b[0m, in \u001b[0;36mwithout_apply_rng.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m(params, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    297\u001b[0m   check_rng_kwarg(kwargs)\n\u001b[0;32m--> 298\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mapply(params, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/transform.py:128\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    122\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    123\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mIf the functions you are transforming use the same names you must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m out, state \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mapply(params, {}, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    130\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mthen use `hk.transform_with_state`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/transform.py:357\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(params\u001b[39m=\u001b[39mparams, state\u001b[39m=\u001b[39mstate, rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    356\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    358\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[556], line 40\u001b[0m, in \u001b[0;36mnet_fn\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     32\u001b[0m embedder \u001b[39m=\u001b[39m jraph\u001b[39m.\u001b[39mGraphMapFeatures(\n\u001b[1;32m     33\u001b[0m   embed_edge_fn\u001b[39m=\u001b[39mhk\u001b[39m.\u001b[39mLinear(E, with_bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), \n\u001b[1;32m     34\u001b[0m   embed_node_fn\u001b[39m=\u001b[39mhk\u001b[39m.\u001b[39mLinear(E, with_bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), \n\u001b[1;32m     35\u001b[0m   embed_global_fn\u001b[39m=\u001b[39mhk\u001b[39m.\u001b[39mLinear(E, with_bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[1;32m     36\u001b[0m net \u001b[39m=\u001b[39m jraph\u001b[39m.\u001b[39mGraphNetwork(\n\u001b[1;32m     37\u001b[0m   update_node_fn\u001b[39m=\u001b[39mnode_update_fn,\n\u001b[1;32m     38\u001b[0m   update_edge_fn\u001b[39m=\u001b[39medge_update_fn,\n\u001b[1;32m     39\u001b[0m   update_global_fn\u001b[39m=\u001b[39mupdate_global_fn)\n\u001b[0;32m---> 40\u001b[0m graph \u001b[39m=\u001b[39m embedder(graph)\n\u001b[1;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m     42\u001b[0m   graph \u001b[39m=\u001b[39m net(graph)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jraph/_src/models.py:331\u001b[0m, in \u001b[0;36mGraphMapFeatures.<locals>.Embed\u001b[0;34m(graphs_tuple)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mEmbed\u001b[39m(graphs_tuple):\n\u001b[1;32m    330\u001b[0m   \u001b[39mreturn\u001b[39;00m graphs_tuple\u001b[39m.\u001b[39m_replace(\n\u001b[0;32m--> 331\u001b[0m       nodes\u001b[39m=\u001b[39membed_nodes_fn(graphs_tuple\u001b[39m.\u001b[39;49mnodes),\n\u001b[1;32m    332\u001b[0m       edges\u001b[39m=\u001b[39membed_edges_fn(graphs_tuple\u001b[39m.\u001b[39medges),\n\u001b[1;32m    333\u001b[0m       \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39membed_global_fn(graphs_tuple\u001b[39m.\u001b[39mglobals))\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/module.py:434\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     local_module_name \u001b[39m=\u001b[39m module_name\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    432\u001b[0m     f \u001b[39m=\u001b[39m stateful\u001b[39m.\u001b[39mnamed_call(f, name\u001b[39m=\u001b[39mlocal_module_name)\n\u001b[0;32m--> 434\u001b[0m out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    436\u001b[0m \u001b[39m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[39m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/module.py:273\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 273\u001b[0m   \u001b[39mreturn\u001b[39;00m bound_method(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    275\u001b[0m ctx \u001b[39m=\u001b[39m MethodContext(module\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m                     method_name\u001b[39m=\u001b[39mmethod_name,\n\u001b[1;32m    277\u001b[0m                     orig_method\u001b[39m=\u001b[39mbound_method)\n\u001b[1;32m    278\u001b[0m interceptor_stack_copy \u001b[39m=\u001b[39m interceptor_stack\u001b[39m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/basic.py:176\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(self, inputs, precision)\u001b[0m\n\u001b[1;32m    174\u001b[0m   stddev \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size)\n\u001b[1;32m    175\u001b[0m   w_init \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39minitializers\u001b[39m.\u001b[39mTruncatedNormal(stddev\u001b[39m=\u001b[39mstddev)\n\u001b[0;32m--> 176\u001b[0m w \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39;49mget_parameter(\u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m, [input_size, output_size], dtype, init\u001b[39m=\u001b[39;49mw_init)\n\u001b[1;32m    178\u001b[0m out \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mdot(inputs, w, precision\u001b[39m=\u001b[39mprecision)\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_bias:\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/base.py:448\u001b[0m, in \u001b[0;36mreplaceable.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 448\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped\u001b[39m.\u001b[39;49m_current(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/haiku/_src/base.py:540\u001b[0m, in \u001b[0;36mget_parameter\u001b[0;34m(name, shape, dtype, init)\u001b[0m\n\u001b[1;32m    537\u001b[0m param \u001b[39m=\u001b[39m check_not_none(param, \u001b[39m\"\u001b[39m\u001b[39mParameters cannot be `None`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m \u001b[39mtuple\u001b[39m(shape):\n\u001b[0;32m--> 540\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    541\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfq_name\u001b[39m!r}\u001b[39;00m\u001b[39m with retrieved shape \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m.\u001b[39mshape\u001b[39m!r}\u001b[39;00m\u001b[39m does not match \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape=\u001b[39m\u001b[39m{\u001b[39;00mshape\u001b[39m!r}\u001b[39;00m\u001b[39m dtype=\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m \u001b[39mreturn\u001b[39;00m param\n",
      "\u001b[0;31mValueError\u001b[0m: 'linear_1/w' with retrieved shape (1, 32) does not match shape=[32, 32] dtype=dtype('float32')"
     ]
    }
   ],
   "source": [
    "evaluate(dataset_processed, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: shapes=[(2,), (1, 10)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/util.py:222\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m   \u001b[39mreturn\u001b[39;00m cached(config\u001b[39m.\u001b[39;49m_trace_context(), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/util.py:215\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcached\u001b[39m(_, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 215\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/lax/lax.py:141\u001b[0m, in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39m@cache\u001b[39m()\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_broadcast_shapes_cached\u001b[39m(\u001b[39m*\u001b[39mshapes: Tuple[\u001b[39mint\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mint\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]:\n\u001b[0;32m--> 141\u001b[0m   \u001b[39mreturn\u001b[39;00m _broadcast_shapes_uncached(\u001b[39m*\u001b[39;49mshapes)\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/lax/lax.py:157\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m result_shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(shapes)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39mreturn\u001b[39;00m result_shape\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(2,), (1, 10)]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m y_ \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mapply(params, x)\n\u001b[1;32m     12\u001b[0m mask \u001b[39m=\u001b[39m jraph\u001b[39m.\u001b[39mget_graph_padding_mask(y_)\n\u001b[1;32m     14\u001b[0m accuracy \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39msum(     \n\u001b[0;32m---> 15\u001b[0m     (jnp\u001b[39m.\u001b[39;49margmax(y_\u001b[39m.\u001b[39;49mglobals, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m==\u001b[39;49m label) \u001b[39m*\u001b[39m mask) \u001b[39m/\u001b[39m jnp\u001b[39m.\u001b[39msum(mask)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mjnp\u001b[39m.\u001b[39margmax(y_\u001b[39m.\u001b[39mglobals,\u001b[39m \u001b[39maxis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(dataset[_][\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m total_accuracy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m accuracy\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:4705\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4703\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m   4704\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m-> 4705\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   4706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m   4707\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsupported operand type(s) for \u001b[39m\u001b[39m{\u001b[39;00mopchar\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4708\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/numpy/ufuncs.py:72\u001b[0m, in \u001b[0;36m_one_to_one_binop.<locals>.<lambda>\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     70\u001b[0m   fn \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x1, x2: lax_fn(\u001b[39m*\u001b[39m_promote_args_numeric(numpy_fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, x1, x2))\n\u001b[1;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m   fn \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x1, x2: lax_fn(\u001b[39m*\u001b[39m_promote_args(numpy_fn\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, x1, x2))\n\u001b[1;32m     73\u001b[0m fn \u001b[39m=\u001b[39m jit(fn, inline\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m lax_doc:\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/numpy/util.py:355\u001b[0m, in \u001b[0;36m_promote_args\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    353\u001b[0m _check_arraylike(fun_name, \u001b[39m*\u001b[39margs)\n\u001b[1;32m    354\u001b[0m _check_no_float0s(fun_name, \u001b[39m*\u001b[39margs)\n\u001b[0;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m _promote_shapes(fun_name, \u001b[39m*\u001b[39;49m_promote_dtypes(\u001b[39m*\u001b[39;49margs))\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/numpy/util.py:248\u001b[0m, in \u001b[0;36m_promote_shapes\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_numpy_rank_promotion \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    247\u001b[0m   _rank_promotion_warning_or_error(fun_name, shapes)\n\u001b[0;32m--> 248\u001b[0m result_rank \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lax\u001b[39m.\u001b[39;49mbroadcast_shapes(\u001b[39m*\u001b[39;49mshapes))\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m [_broadcast_to(arg, (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m (result_rank \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(shp)) \u001b[39m+\u001b[39m shp)\n\u001b[1;32m    250\u001b[0m         \u001b[39mfor\u001b[39;00m arg, shp \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args, shapes)]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jraph/lib/python3.10/site-packages/jax/_src/lax/lax.py:157\u001b[0m, in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    155\u001b[0m result_shape \u001b[39m=\u001b[39m _try_broadcast_shapes(shape_list)\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m result_shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncompatible shapes for broadcasting: shapes=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(shapes)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39mreturn\u001b[39;00m result_shape\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: shapes=[(2,), (1, 10)]"
     ]
    }
   ],
   "source": [
    "c, n = 0, 0\n",
    "total_accuracy = 0.\n",
    "for _ in range(len(dataset)):\n",
    "\n",
    "    x = dataset_processed[_][\"input_graph\"]\n",
    "    label = dataset_processed[_][\"target\"]\n",
    "    #x = pad_graph_to_nearest_power_of_two(x)\n",
    "    x = pad_graph_to_value(x, PAD_VALUE)\n",
    "    # label = jnp.concatenate([label, jnp.array([0])])\n",
    "\n",
    "    y_ = net.apply(params, x)\n",
    "    mask = jraph.get_graph_padding_mask(y_)\n",
    "\n",
    "    accuracy = jnp.sum(     \n",
    "        (jnp.argmax(y_.globals, axis=1) == label) * mask) / jnp.sum(mask)\n",
    "    print(f\"{jnp.argmax(y_.globals, axis=1)[0]} {int(dataset[_]['target'])}\")\n",
    "\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "    total_accuracy /= _\n",
    "    print(f\"ACCURACY = {total_accuracy:.2f}%\")\n",
    "\n",
    "    # Try rotating the graph to test invariance of classification\n",
    "    print(\"TESTING ROTATION INVARIANCE.\")\n",
    "    key = jr.PRNGKey(1294)\n",
    "    n_test = 10\n",
    "    ix = jr.randint(key, shape=(n_test,), minval=0, maxval=n_test)\n",
    "    dataset = get_rotated_mnist_graphs(\n",
    "    X[ix], Y[ix], n_graphs=n_test, r_link=R_LINK, plot=True)\n",
    "\n",
    "    for i in range(n_test):\n",
    "        x, y = dataset_processed[i][\"input_graph\"], dataset_processed[i][\"target\"]\n",
    "        x = pad_graph_to_value(x, PAD_VALUE)\n",
    "        # label = jnp.concatenate([y, jnp.array([0])])\n",
    "\n",
    "        y_ = net.apply(params, x)\n",
    "        mask = jraph.get_graph_padding_mask(y_) \n",
    "\n",
    "        # accuracy = jnp.sum(     \n",
    "        #     (jnp.argmax(y_.globals, axis=1) == y) * mask) / jnp.sum(mask)\n",
    "\n",
    "        # no mask, globals stay same size always?\n",
    "        accuracy = jnp.sum(jnp.argmax(y_.globals, axis=1) == y) \n",
    "        print(f\"{jnp.argmax(y_.globals, axis=1)[0]} {int(dataset[i]['target'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89eacdfae071486057d2d630fe016cfa1eafc53aeae1b159d8d57a4fae204a68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
